### Functions

# # get the data
# loader = function() {
#   train_df = read_csv(here::here("data/train.csv"))
#   test_df = read_csv(here::here("data/test.csv")) # we are going to drop this later! just including it for clarity
#   df_list = list(train_df, test_df)
#   df_list
# }

# get the data
loader = function() {
  df= read_csv(here::here("data/train.csv"))
  df
}

# counter
counter = function(x) {
  (sum(is.na(x))/length(x))
}

# lumper (to lump small factor levels)
lumper = function(x, perc_lump) {
  fct_lump(x, prop = perc_lump)
}

# combine and format the data
combiner = function(data, list = NULL, perc_miss, perc_lump) {
  x = data %>%
    clean_names() %>% # clean column names
    mutate_if(is.character, as.factor) %>% # mutate character columns to factors
    mutate_at(vars(c(contains("year"), contains("yr"), contains("class"))), as.factor) %>% 
    mutate_at(list, as.factor)
  #rowid_to_column("id") # need to make if_then version of this 
  y = map_df(x, counter) %>% # get variables that have fewer than 20% of their values missing 
    pivot_longer(-id, names_to = "values", values_to = "count") %>%
    select(-id) %>%
    filter(count < perc_miss) %>%
    pull(values)
  z_factors = x %>%
    select(one_of(y)) %>% # filter the df from x to the subset of cols in y
    drop_na() %>% # drop rows containing NAs 
    mutate_if(is.factor, function(u) lumper(u, perc_lump)) %>%  # lump levels of factors together into "other" if they are 10% or fewer of the observed vals
    mutate_if(is.factor, function(x) lumper(x, -0.89)) %>% # lump levels of factors together if any level shows up > 89% of the time
    select_if(is.factor) # drop non-factor variables
  z_factors2 = z_factors[, sapply(z_factors, nlevels) > 1]  # EVERYTHING BETWEEN HERE IS GROSS
  z_factors3 = sapply(z_factors2, fct_drop) %>% 
    as_tibble()
  z_factors4 = z_factors3[, sapply(z_factors3, function(x) length(unique(x))) > 1] %>% 
    as_tibble() %>% 
    mutate_if(is.character, as.factor) %>% 
    rowid_to_column() # EVERYTHING BETWEEN HERE IS GROSS
  z = x %>%
    select(one_of(y)) %>% # filter the df from x to the subset of cols in y
    select_if(is.numeric) %>% 
    drop_na() %>% # drop rows containing NAs 
    rowid_to_column() %>% 
    inner_join(z_factors4, by = "rowid") %>% 
    select(-rowid)
  z
}

tasker = function(data, id, target) { # data: df produced by combiner (dataframe), id: identifier for the new task (string), target: column in df 
  # that corresponds to the target vector of our model (vector)
  task = TaskRegr$new(id = id, backend = data, target = target)
  task
}

learn_gener = function(lrn_list) { # ... : a vector of learners (e.g c("regr.rpart", "regr.ranger"))
  learners = map(lrn_list, lrn, predict_sets = c("train", "test"))
  learners
}

splitter = function(data, prop, seed) { # x: an mlr3 task (TaskRegr), prop: proportion of data for train set (scalar), seed: random seed (scalar)
  set.seed(seed)                        # returns a list of row ids 
  train = sample(data$nrow, prop*data$nrow)
  test = setdiff(seq_len(data$nrow), train)
  list(train, test)
}

trainer = function(learners, task, df_list) { # learners: list of learners generated by learn_gener (list), task: mlr3 task generated by tasker (TaskRegr),
  # df_list: list of dataframes generated by splitter (list)
  trained_learners = lapply(learners, function(x) x$train(task, row_ids = df_list[[1]]))
  trained_learners
}

resampler = function(method, folds, seed) {
  set.seed(seed)
  method = rsmp(method, folds = folds)
  method
}

benchmarker = function(task, learners, resampling, measures) {
  measures_loaded = c(lapply(measures, function(x) msr(x, id = str_c(x, "train", sep = "_"), predict_sets = "train")), 
                      lapply(measures, function(x) msr(x, id = str_c(x, "test", sep = "_"), predict_sets = "test")))
  design = benchmark_grid(task, learners, resampling)
  bmr = benchmark(design)
  bmr_done = bmr$aggregate(measures_loaded)
  bmr_done
}

predictor = function(trained_model, task, test_ids) {
  preds = lapply(trained_model, function(x) x$predict(task, row_ids = test_ids))
  preds
}

fixer = function(task, target) {
  target_free = as_tibble(task$data()) %>% select(-target)
  target_vec = as_tibble(task$data()) %>% select(target) %>% pull()
  list(target_free, target_vec)
}

imler_local = function(trained_learners, lrn_list, data, target, observation){
  preds = lapply(trained_learners, function(x) Predictor$new(x, data = as_tibble(data), 
                                                             y = target))
  limes = lapply(preds, function(x) LocalModel$new(x, x.interest = as_tibble(data) %>% slice(observation), k = 10))
  shaps = lapply(preds, function(x) Shapley$new(x, x.interest = as_tibble(data) %>% slice(observation)))
  lime_plots = lapply(limes, function(x) ggplot(as_tibble(x$results), aes(reorder(x$results$feature.value, x$results$effect), x$results$effect)) +
                        geom_bar(stat = "identity") +
                        coord_flip())
  shap_plots = lapply(shaps, function(x) ggplot(as_tibble(x$results), aes(reorder(x$results$feature.value, x$results$phi), x$results$phi)) +
                        geom_bar(stat = "identity") +
                        coord_flip())
  lime_plots2 = list()
  shap_plots2 = list()
  for (i in 1:length(trained_learners)) {
    lime_plots2[[i]] = lime_plots[[i]] +
      labs(x = "Feature Value", y= "Feature Effect (on prediction)", title = paste("LIME Effects for Model", lrn_list[[i]], "at Observation", observation))
  }
  for (i in 1:length(trained_learners)) {
    shap_plots2[[i]] = shap_plots[[i]] + 
      labs(x = "Feature Values", y = "Phi (Shapley Value)", title = paste("Shapley Values for Model", lrn_list[[i]], "at Observation", observation))
  }
  list(lime_plots2, shap_plots2)
}

imler_permutation = function(trained_learners, lrn_list, data, target) {
  preds = lapply(trained_learners, function(x) Predictor$new(x, data = as_tibble(data), 
                                                             y = target))
  imps = lapply(preds, function(x) FeatureImp$new(x, loss = "mae"))
  smol_imps = lapply(imps, function(x) x$results %>% top_n(20))
  global_plots = lapply(smol_imps, function(x) ggplot(x, aes(importance, reorder(feature, importance))) + 
                       geom_point(size = 3) +
                       geom_errorbarh(aes(xmin = importance.05, xmax = importance.95), size = 0.3))
  imp_plots2 = list()
  for (i in 1:length(trained_learners)) {
    imp_plots2[[i]] = global_plots[[i]] + 
      labs(x = "Importance", y = "Feature", title = paste("Permutation importance for", lrn_list[[i]]))
  }
  imp_plots2
}

imler_global_plots = function(trained_learners, lrn_list, data, target, feature = NULL) {
  preds = lapply(trained_learners, function(x) Predictor$new(x, data = as_tibble(data), 
                                                             y = target))
    pdp_data = lapply(preds, function(x) FeatureEffects$new(x, method = "pdp", feature = feature))
    pdp_data_cleaned = list()
    for (i in 1:length(pdp_data)) {
      pdp_data_cleaned[[i]] = pdp_data[[i]]$results %>% 
        data.frame() %>% 
        as_tibble() %>% 
        rename(feature_val = 1,  # THIS NEEDS TO BE FIXED 
                  y_hat = 2,
                  type = 3)
    }
    pdp_plots = lapply(pdp_data_cleaned, function(x) ggplot(x, aes(feature_val, y_hat)) + 
                         geom_line())
    pdp_plots2 = list()
    for (i in 1:length(trained_learners)) {
      pdp_plots2[[i]] = pdp_plots[[i]] +
        labs(x = "Permuted Feature Value", y= "Y-hat", title = paste("PDP for Model", lrn_list[[i]], "on Feature", feature))
    }
    pdp_ice_data = lapply(preds, function(x) FeatureEffects$new(x, method = "pdp+ice", feature = feature))
    pdp_ice_data_cleaned = list()
    for (i in 1:length(pdp_ice_data)) { 
      pdp_ice_data_cleaned[[i]] = pdp_ice_data[[i]]$results %>% 
        data.frame() %>% 
        as_tibble() %>% 
        rename(feature_val = 1,  # THIS NEEDS TO BE FIXED
                  y_hat = 2,
                  type = 3,
                  id = 4)
    }
    ice_plots = list()
    for (i in 1:length(pdp_ice_data)) {
      ice_plots[[i]] = ggplot() + 
        geom_line(pdp_ice_data_cleaned[[i]] %>% filter(type == "ice"), mapping = aes(feature_val, y_hat/1000, group = id), alpha = 0.2) +
        labs(x = "Feature Value", y = "Sale Price in Thousands", title = paste("ICE Plot of Sale Price for", lrn_list[[i]], "on Feature", feature))
    }
    pdp_ice_plots = list()
    for (i in 1:length(pdp_ice_data)) {
      pdp_ice_plots[[i]] = ggplot() + 
        geom_line(pdp_ice_data_cleaned[[i]] %>% filter(type == "ice"), mapping = aes(feature_val, y_hat/1000, group = id), alpha = 0.2) +
        geom_line(pdp_ice_data_cleaned[[i]] %>% filter(type == "pdp"), mapping = aes(feature_val, y_hat/1000), color = "red", size = 3) +
        labs(x = "Feature Value", y = "Sale Price in Thousands", title = paste("PDP/ICE Plot of Sale Price for", lrn_list[[i]], "on Feature", feature))
    }
    ale_data = lapply(preds, function(x) FeatureEffects$new(x, method = "ale", feature = feature))
    ale_data_cleaned = list()
    for (i in 1:length(ale_data)) {
      ale_data_cleaned[[i]] = ale_data[[i]]$results %>% 
        data.frame() %>% 
        as_tibble() %>% 
        select(3, 1) %>% 
        rename(feature_val = 1, # THIS NEEDS TO BE FIXED
                  ale = 2)
    }
    ale_plots = lapply(ale_data_cleaned, function(x) ggplot(x, aes(feature_val, ale)) + 
                         geom_line())
    ale_plots2 = list()
    for (i in 1:length(trained_learners)) {
      ale_plots2[[i]] = ale_plots[[i]] +
        labs(x = "Permuted Feature Value", y= "ALE", title = paste("ALE for Model", lrn_list[[i]], "on Feature", feature))
    }
  list(pdp_plots2, ice_plots, pdp_ice_plots, ale_plots2)
} 

